services:
  langgraph_streamlit:
    container_name: langgraph_streamlit
    build:
      context: .
      dockerfile: Dockerfile
      target: backend
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app/app
      - faiss_data:/app/vectorstore
    environment:
      TMPDIR: /tmp
      TEMP: /tmp
      TMP: /tmp
      OPENAI_API_KEY: ${OPENAI_API_KEY}  # Add this line
    tmpfs:
      - /tmp
    restart: unless-stopped

  streamlit_app:
    container_name: streamlit_app
    build:
      context: .
      dockerfile: Dockerfile
      target: streamlit
    ports:
      - "8501:8501"
    volumes:
      - ./app:/app/app
      - faiss_data:/app/vectorstore
    environment:
      BACKEND_URL: http://langgraph_streamlit:8000
      TMPDIR: /tmp
      TEMP: /tmp
      TMP: /tmp
      STREAMLIT_SERVER_FILE_WATCHER_TYPE: none
      OPENAI_API_KEY: ${OPENAI_API_KEY}  # Add this line
    tmpfs:
      - /tmp
    depends_on:
      - langgraph_streamlit
    command: >
      streamlit run app/streamlit/main.py
      --server.port=8501
      --server.address=0.0.0.0
    restart: unless-stopped

volumes:
  faiss_data: